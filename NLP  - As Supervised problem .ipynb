{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# As supervised problem - NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\femis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz#egg=en_core_web_sm==2.1.0 in c:\\users\\femis\\anaconda3\\lib\\site-packages (2.1.0)\n",
      "[+] Download and installation successful\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "symbolic link created for C:\\Users\\femis\\Anaconda3\\lib\\site-packages\\spacy\\data\\en <<===>> C:\\Users\\femis\\Anaconda3\\lib\\site-packages\\en_core_web_sm\n",
      "[+] Linking successful\n",
      "C:\\Users\\femis\\Anaconda3\\lib\\site-packages\\en_core_web_sm -->\n",
      "C:\\Users\\femis\\Anaconda3\\lib\\site-packages\\spacy\\data\\en\n",
      "You can now load the model via spacy.load('en')\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "from collections import Counter\n",
    "import nltk\n",
    "\n",
    "nltk.download('gutenberg')\n",
    "!python -m spacy download en\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised NLP requires a pre-labelled dataset for training and testing, and is generally interested in categorizing text in various ways. In this case, we are going to try to PREDICT whether a sentence comes from Alice in Wonderland by Lewis Carroll or Persuasion by Jane Austen. We can use any of the supervised models we've covered previously, as long as they allow categorical outcomes. In this case, we'll try RANDOM FORESTS, SVM, and KNN.\n",
    "\n",
    "Our FEATURE-GENERATION approach will be something called BoW, or Bag of Words. BoW is quite simple: For each sentence, we count how many times each word appears. We will then use those counts as features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Since processing all the text takes around ~5-10 minutes, in the cell below we are taking only the first tenth of each text. If you want to experiment, feel free to change the following code in the next cell:\n",
    "\n",
    "alice = text_cleaner(alice[:int(len(alice)/10)])\n",
    "\n",
    "persuasion = text_cleaner(persuasion[:int(len(persuasion)/10)])\n",
    "\n",
    "to\n",
    "\n",
    "alice = text_cleaner(alice)\n",
    "\n",
    "persuasion = text_cleaner(persuasion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function for standard text cleaning.\n",
    "def text_cleaner(text):\n",
    "    # Visual inspection identifies a form of punctuation spaCy does not\n",
    "    # recognize: the double dash '--'.  Better get rid of it now!\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "    \n",
    "# Load and clean the data.\n",
    "persuasion = gutenberg.raw('austen-persuasion.txt')\n",
    "alice = gutenberg.raw('carroll-alice.txt')\n",
    "\n",
    "# The Chapter indicator is idiosyncratic\n",
    "persuasion = re.sub(r'Chapter \\d+', '', persuasion)\n",
    "alice = re.sub(r'CHAPTER .*', '', alice)\n",
    "    \n",
    "alice = text_cleaner(alice[:int(len(alice)/10)])\n",
    "persuasion = text_cleaner(persuasion[:int(len(persuasion)/10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the cleaned novels. This can take a bit.\n",
    "nlp = spacy.load('en')\n",
    "alice_doc = nlp(alice)\n",
    "persuasion_doc = nlp(persuasion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Alice, was, beginning, to, get, very, tired, ...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0        1\n",
       "0  (Alice, was, beginning, to, get, very, tired, ...  Carroll\n",
       "1  (So, she, was, considering, in, her, own, mind...  Carroll\n",
       "2  (There, was, nothing, so, VERY, remarkable, in...  Carroll\n",
       "3                                      (Oh, dear, !)  Carroll\n",
       "4                                      (Oh, dear, !)  Carroll"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group into sentences.\n",
    "alice_sents = [[sent, \"Carroll\"] for sent in alice_doc.sents]\n",
    "persuasion_sents = [[sent, \"Austen\"] for sent in persuasion_doc.sents]\n",
    "\n",
    "# Combine the sentences from the two novels into one data frame.\n",
    "sentences = pd.DataFrame(alice_sents + persuasion_sents)\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to bag some words! Since spaCy has already tokenized and labelled our data, we can move directly to recording how often various words occur. We will exclude stopwords and punctuation. In addition, in an attempt to keep our feature space from exploding, we will work with lemmas (root words) rather than the raw text terms, and we'll only use the 2000 most common words for each text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to create a list of the 2000 most common words.\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # Filter out punctuation and stop words.\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    # Return the most common words.\n",
    "    return [item[0] for item in Counter(allwords).most_common(2000)]\n",
    "    \n",
    "\n",
    "# Creates a data frame with features for each word in our common word set.\n",
    "# Each value is the count of the times the word appears in each sentence.\n",
    "def bow_features(sentences, common_words):\n",
    "    \n",
    "    # Scaffold the data frame and initialize counts to zero.\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df['text_source'] = sentences[1]\n",
    "    df.loc[:, common_words] = 0\n",
    "    \n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        \n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        \n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        \n",
    "        # This counter is just to make sure the kernel didn't hang.\n",
    "        if i % 50 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "            \n",
    "    return df\n",
    "\n",
    "# Set up the bags.\n",
    "alicewords = bag_of_words(alice_doc)\n",
    "persuasionwords = bag_of_words(persuasion_doc)\n",
    "\n",
    "# Combine bags to create a set of unique words.\n",
    "common_words = set(alicewords + persuasionwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 50\n",
      "Processing row 100\n",
      "Processing row 150\n",
      "Processing row 200\n",
      "Processing row 250\n",
      "Processing row 300\n",
      "Processing row 350\n",
      "Processing row 400\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>farther</th>\n",
       "      <th>propose</th>\n",
       "      <th>judge</th>\n",
       "      <th>reserve</th>\n",
       "      <th>volume</th>\n",
       "      <th>horribly</th>\n",
       "      <th>stop</th>\n",
       "      <th>ball</th>\n",
       "      <th>breeding</th>\n",
       "      <th>far</th>\n",
       "      <th>...</th>\n",
       "      <th>originally</th>\n",
       "      <th>regular</th>\n",
       "      <th>alarm</th>\n",
       "      <th>wear</th>\n",
       "      <th>public</th>\n",
       "      <th>admit</th>\n",
       "      <th>rejoice</th>\n",
       "      <th>perfection</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Alice, was, beginning, to, get, very, tired, ...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1614 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  farther propose judge reserve volume horribly stop ball breeding far  \\\n",
       "0       0       0     0       0      0        0    0    0        0   0   \n",
       "1       0       0     0       0      0        0    0    0        0   0   \n",
       "2       0       0     0       0      0        0    0    0        0   0   \n",
       "3       0       0     0       0      0        0    0    0        0   0   \n",
       "4       0       0     0       0      0        0    0    0        0   0   \n",
       "\n",
       "      ...     originally regular alarm wear public admit rejoice perfection  \\\n",
       "0     ...              0       0     0    0      0     0       0          0   \n",
       "1     ...              0       0     0    0      0     0       0          0   \n",
       "2     ...              0       0     0    0      0     0       0          0   \n",
       "3     ...              0       0     0    0      0     0       0          0   \n",
       "4     ...              0       0     0    0      0     0       0          0   \n",
       "\n",
       "                                       text_sentence text_source  \n",
       "0  (Alice, was, beginning, to, get, very, tired, ...     Carroll  \n",
       "1  (So, she, was, considering, in, her, own, mind...     Carroll  \n",
       "2  (There, was, nothing, so, VERY, remarkable, in...     Carroll  \n",
       "3                                      (Oh, dear, !)     Carroll  \n",
       "4                                      (Oh, dear, !)     Carroll  \n",
       "\n",
       "[5 rows x 1614 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create our data frame with features. This can take a while to run.\n",
    "word_counts = bow_features(sentences, common_words)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "farther            object\n",
       "propose            object\n",
       "judge              object\n",
       "reserve            object\n",
       "volume             object\n",
       "horribly           object\n",
       "stop               object\n",
       "ball               object\n",
       "breeding           object\n",
       "far                object\n",
       "history            object\n",
       "poor               object\n",
       "particularly       object\n",
       "comprehensive      object\n",
       "undesirableness    object\n",
       "surprised          object\n",
       "perpetuate         object\n",
       "intimate           object\n",
       "present            object\n",
       "quarter            object\n",
       "right              object\n",
       "disposed           object\n",
       "shortly            object\n",
       "involve            object\n",
       "sir                object\n",
       "worth              object\n",
       "father             object\n",
       "prefer             object\n",
       "easily             object\n",
       "conduct            object\n",
       "                    ...  \n",
       "size               object\n",
       "letter             object\n",
       "tiding             object\n",
       "keep               object\n",
       "curious            object\n",
       "near               object\n",
       "dictate            object\n",
       "20                 object\n",
       "awful              object\n",
       "pride              object\n",
       "debt               object\n",
       "neighbourhood      object\n",
       "put                object\n",
       "continually        object\n",
       "foot               object\n",
       "accurately         object\n",
       "sister             object\n",
       "Mrs                object\n",
       "connection         object\n",
       "originally         object\n",
       "regular            object\n",
       "alarm              object\n",
       "wear               object\n",
       "public             object\n",
       "admit              object\n",
       "rejoice            object\n",
       "perfection         object\n",
       "text_sentence      object\n",
       "text_source         int64\n",
       "text_source_cat      int8\n",
       "Length: 1615, dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts[\"text_source\"] = word_counts[\"text_source\"].astype('int64')\n",
    "\n",
    "word_counts.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>farther</th>\n",
       "      <th>propose</th>\n",
       "      <th>judge</th>\n",
       "      <th>reserve</th>\n",
       "      <th>volume</th>\n",
       "      <th>horribly</th>\n",
       "      <th>stop</th>\n",
       "      <th>ball</th>\n",
       "      <th>breeding</th>\n",
       "      <th>far</th>\n",
       "      <th>...</th>\n",
       "      <th>regular</th>\n",
       "      <th>alarm</th>\n",
       "      <th>wear</th>\n",
       "      <th>public</th>\n",
       "      <th>admit</th>\n",
       "      <th>rejoice</th>\n",
       "      <th>perfection</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "      <th>text_source_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Alice, was, beginning, to, get, very, tired, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1615 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  farther propose judge reserve volume horribly stop ball breeding far  \\\n",
       "0       0       0     0       0      0        0    0    0        0   0   \n",
       "1       0       0     0       0      0        0    0    0        0   0   \n",
       "2       0       0     0       0      0        0    0    0        0   0   \n",
       "3       0       0     0       0      0        0    0    0        0   0   \n",
       "4       0       0     0       0      0        0    0    0        0   0   \n",
       "\n",
       "        ...       regular alarm wear public admit rejoice perfection  \\\n",
       "0       ...             0     0    0      0     0       0          0   \n",
       "1       ...             0     0    0      0     0       0          0   \n",
       "2       ...             0     0    0      0     0       0          0   \n",
       "3       ...             0     0    0      0     0       0          0   \n",
       "4       ...             0     0    0      0     0       0          0   \n",
       "\n",
       "                                       text_sentence text_source  \\\n",
       "0  (Alice, was, beginning, to, get, very, tired, ...           1   \n",
       "1  (So, she, was, considering, in, her, own, mind...           1   \n",
       "2  (There, was, nothing, so, VERY, remarkable, in...           1   \n",
       "3                                      (Oh, dear, !)           1   \n",
       "4                                      (Oh, dear, !)           1   \n",
       "\n",
       "  text_source_cat  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "\n",
       "[5 rows x 1615 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "word_counts[\"text_source_cat\"] = word_counts[\"text_source\"].cat.codes\n",
    "\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BoW with Random Forest\n",
    "\n",
    "Now let's give the bag of words features a whirl by trying a random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\femis\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.9736842105263158\n",
      "\n",
      "Test set score: 0.8539325842696629\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "Y = word_counts['text_source']\n",
    "y = word_counts['text_source_cat']\n",
    "\n",
    "X = np.array(word_counts.drop(['text_sentence','text_source','text_source_cat'], 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    Y,\n",
    "                                                    test_size=0.4,\n",
    "                                                    random_state=0)\n",
    "train = rfc.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score:', rfc.score(X_train, y_train))\n",
    "print('\\nTest set score:', rfc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Holy overfitting, Batman! Overfitting is a known problem when using bag of words, since it basically involves throwing a massive number of features at a model – some of those features (in this case, word frequencies) will capture noise in the training set. Since overfitting is also a known problem with Random Forests, the divergence between training score and test score is expected.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\femis\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC()\n",
    "svc.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1d78c7c2320>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's see what a scatter plot looks like, comparing actuals to predicted.\n",
    "\n",
    "plt.scatter(Y, svc.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7094594594594594"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  scores of both our full fit model and with cross validation\n",
    "svc.score(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\femis\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\femis\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\femis\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\femis\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\femis\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.70786517, 0.70786517, 0.70786517, 0.70786517, 0.71590909])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(svc, X, Y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate our model and fit the data.\n",
    "svm = SVC(kernel = 'linear')\n",
    "svm.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9797297297297297"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.score(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.85393258, 0.84269663, 0.87640449, 0.85393258, 0.82954545])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(svm, X, Y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets try using PCA with SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\femis\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\femis\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Create a scaler object\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the features and transform\n",
    "X_std = sc.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition, datasets\n",
    "\n",
    "# Create a pca object with the 2 components as a parameter\n",
    "pca = decomposition.PCA(n_components=2)\n",
    "\n",
    "# Fit the PCA and transform the data\n",
    "X_std_pca = pca.fit_transform(X_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(444, 2)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the new feature data's shape\n",
    "X_std_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-7.83993644e-01, -3.72311515e-01],\n",
       "       [-8.06297564e-01, -4.73316431e-01],\n",
       "       [-5.81333437e-01,  1.02776064e-01],\n",
       "       [-6.02286426e-01, -6.83655087e-01],\n",
       "       [-6.02286426e-01, -6.83655087e-01],\n",
       "       [-6.13795990e-01, -6.84536729e-01],\n",
       "       [-6.94302418e-01, -7.85191240e-01],\n",
       "       [-6.58655589e-01, -5.56158026e-01],\n",
       "       [-1.09099360e+00, -1.26845872e+00],\n",
       "       [-6.54582355e-01, -7.11023777e-01],\n",
       "       [-9.21647003e-01, -1.02565541e+00],\n",
       "       [-7.47836798e-01, -6.46695235e-01],\n",
       "       [-6.05992109e-01, -3.05126954e-01],\n",
       "       [-7.49789325e-01, -5.26125756e-01],\n",
       "       [-6.95405705e-01, -7.62858919e-01],\n",
       "       [-7.09266079e-01, -7.79832843e-01],\n",
       "       [-6.14430592e-01, -6.20247915e-01],\n",
       "       [-5.87866159e-01, -6.11873975e-01],\n",
       "       [-5.66495555e-01, -5.09034762e-01],\n",
       "       [-5.73431554e-01, -6.50495164e-01],\n",
       "       [-5.96736306e-01, -5.10098516e-01],\n",
       "       [-6.33314617e-01, -6.64162396e-01],\n",
       "       [-6.03318864e-01, -6.67812715e-01],\n",
       "       [-6.50955710e-01, -7.37326291e-01],\n",
       "       [-9.14977899e-01, -3.85391496e-01],\n",
       "       [-6.54430911e-01, -7.48733537e-01],\n",
       "       [-6.09316492e-01, -7.47907738e-01],\n",
       "       [-6.10266443e-01, -6.94523844e-01],\n",
       "       [-6.52845431e-01, -7.64168661e-01],\n",
       "       [-6.43434780e-01, -5.44445464e-01],\n",
       "       [-6.05684946e-01, -6.83028547e-01],\n",
       "       [-5.59143828e-01, -5.48845153e-01],\n",
       "       [-5.46301342e-01, -1.09603036e-02],\n",
       "       [-6.58346801e-01, -7.66926981e-01],\n",
       "       [-7.18379825e-01, -8.08939670e-01],\n",
       "       [-6.06767525e-01, -6.85256898e-01],\n",
       "       [-6.26212528e-01, -6.09101897e-01],\n",
       "       [-6.12763281e-01, -6.24582616e-01],\n",
       "       [-5.73431554e-01, -6.50495164e-01],\n",
       "       [-6.29829919e-01, -6.33262938e-01],\n",
       "       [-6.47715646e-01, -7.38221073e-01],\n",
       "       [-6.02835016e-01, -6.86106574e-01],\n",
       "       [-6.65091297e-01, -7.88052148e-01],\n",
       "       [-5.97388480e-01, -6.82490179e-01],\n",
       "       [-5.20246672e-01, -8.53720190e-02],\n",
       "       [-6.81218419e-01, -5.79302553e-01],\n",
       "       [-6.46781162e-01, -7.20089538e-01],\n",
       "       [-7.80199495e-01, -8.35005185e-01],\n",
       "       [-6.75815100e-01, -7.32523001e-01],\n",
       "       [-5.70840895e-01, -6.41428815e-01],\n",
       "       [-6.79673641e-01, -5.40148384e-01],\n",
       "       [-6.11944365e-01, -6.98618590e-01],\n",
       "       [-5.92888362e-01, -6.76559900e-01],\n",
       "       [-5.82213739e-01, -2.93068215e-01],\n",
       "       [-8.31289634e-01, -7.00625252e-02],\n",
       "       [-6.33433818e-01,  8.19401813e-02],\n",
       "       [-7.60858066e-01, -1.55511305e-01],\n",
       "       [-5.93822951e-01, -6.83508842e-01],\n",
       "       [-7.97848736e-01, -9.29827481e-01],\n",
       "       [-9.01286504e-01, -9.18471794e-01],\n",
       "       [-7.00534515e-01, -7.55943523e-01],\n",
       "       [ 9.45748568e-01, -8.27400567e-01],\n",
       "       [-5.79859433e-01, -8.22336898e-01],\n",
       "       [-8.66462901e-01, -6.90215667e-01],\n",
       "       [-9.30735653e-01, -3.04517806e-01],\n",
       "       [-6.11217894e-01, -1.90914617e-01],\n",
       "       [-5.91439218e-01, -4.84104184e-01],\n",
       "       [-7.08642296e-01, -7.76091235e-01],\n",
       "       [-1.10516326e+00, -1.09679150e+00],\n",
       "       [-6.67042980e-01, -7.18509810e-01],\n",
       "       [ 6.20001618e-02,  9.86448364e-02],\n",
       "       [-1.13304972e+00, -1.09500745e+00],\n",
       "       [-5.73431554e-01, -6.50495164e-01],\n",
       "       [-7.14533622e-01, -7.78220756e-01],\n",
       "       [-5.73431554e-01, -6.50495164e-01],\n",
       "       [-4.27224575e-01, -8.53653724e-01],\n",
       "       [-6.40681070e-01, -7.03865174e-01],\n",
       "       [ 1.30147546e+00, -5.60570263e-01],\n",
       "       [-6.03159385e-01, -6.95507423e-01],\n",
       "       [-6.88403345e-01, -4.67778922e-01],\n",
       "       [-7.29956938e-01, -8.01695098e-01],\n",
       "       [-1.18738285e+00, -1.28550614e+00],\n",
       "       [-7.28853950e-01, -5.78912859e-01],\n",
       "       [-4.16370210e-01, -1.42995305e-01],\n",
       "       [-6.78429598e-01, -7.28893814e-01],\n",
       "       [ 1.27805201e+00, -9.53456959e-01],\n",
       "       [-8.22542914e-01, -8.55067384e-01],\n",
       "       [-8.10239336e-01, -7.41408996e-01],\n",
       "       [-6.40066004e-01, -6.44027796e-01],\n",
       "       [-5.83327026e-01, -6.57560395e-01],\n",
       "       [-9.22043977e-01, -5.07312658e-01],\n",
       "       [-6.40690033e-01, -7.38154070e-01],\n",
       "       [-5.73431554e-01, -6.50495164e-01],\n",
       "       [-6.12958272e-01, -7.03811620e-01],\n",
       "       [-7.89314285e-01, -8.73554778e-01],\n",
       "       [-6.25700601e-01, -6.86184617e-01],\n",
       "       [-6.44865879e-01, -5.20105808e-01],\n",
       "       [-7.30397396e-01, -8.16824020e-01],\n",
       "       [-5.82204965e-01, -5.84383932e-01],\n",
       "       [-6.33902115e-01, -7.84756719e-01],\n",
       "       [-5.99542345e-01, -3.21178246e-01],\n",
       "       [-6.29097669e-01, -7.26295107e-01],\n",
       "       [-6.66700452e-01, -7.71244360e-01],\n",
       "       [-6.05983426e-01, -5.01492752e-01],\n",
       "       [-6.30127778e-01, -7.61652019e-01],\n",
       "       [-6.82717463e-01, -8.02114670e-01],\n",
       "       [-6.32577795e-01, -6.64406505e-01],\n",
       "       [-5.43756377e-01, -7.32776021e-01],\n",
       "       [-6.22298072e-01, -7.02143770e-01],\n",
       "       [-7.02492736e-01, -5.76182006e-01],\n",
       "       [-5.62667569e-01, -7.82532886e-01],\n",
       "       [-6.26391892e-01, -7.02817871e-01],\n",
       "       [-7.02166229e-01, -8.11185728e-01],\n",
       "       [-6.72461982e-01, -7.72969851e-01],\n",
       "       [-6.02084016e-01,  3.87392571e-01],\n",
       "       [-5.70910529e-01, -4.01601208e-01],\n",
       "       [-5.92535325e-01, -6.76085169e-01],\n",
       "       [-5.92093413e-01, -6.67131490e-01],\n",
       "       [-5.45313271e-01,  1.65499143e-01],\n",
       "       [-9.46426684e-01, -1.37760453e-01],\n",
       "       [-6.55894448e-01,  1.61565095e-01],\n",
       "       [-5.93817581e-01, -6.83542358e-01],\n",
       "       [-5.17389115e-01, -6.41703937e-01],\n",
       "       [ 3.51465422e-01, -8.62809527e-01],\n",
       "       [-5.78136199e-01, -5.81393451e-01],\n",
       "       [-5.68847960e-01, -2.34849283e-01],\n",
       "       [-6.01752586e-01, -3.84851958e-01],\n",
       "       [-5.77782611e-01, -6.45515981e-01],\n",
       "       [-5.92535325e-01, -6.76085169e-01],\n",
       "       [ 4.56895446e+00,  1.21541277e+01],\n",
       "       [ 7.49374968e-01, -1.05070912e+00],\n",
       "       [-5.73431554e-01, -6.50495164e-01],\n",
       "       [ 6.15499360e+00, -2.55362104e+00],\n",
       "       [-2.86809881e-01, -1.15448277e+00],\n",
       "       [-5.73431554e-01, -6.50495164e-01],\n",
       "       [ 1.42996208e+01, -3.71053242e+00],\n",
       "       [ 1.14373996e+02, -1.36456433e+01],\n",
       "       [-5.73431554e-01, -6.50495164e-01],\n",
       "       [-1.23982663e-01, -5.91627252e-01],\n",
       "       [ 2.54900325e-02,  4.37112181e-02],\n",
       "       [-6.26978604e-01,  1.56702730e-01],\n",
       "       [-7.61273105e-02, -3.35144703e-01],\n",
       "       [-4.00867303e-01, -5.03023551e-01],\n",
       "       [-4.42031727e-01, -7.62160782e-01],\n",
       "       [-5.16382209e-01, -9.81153282e-01],\n",
       "       [-8.58437196e-01, -1.01020011e+00],\n",
       "       [ 8.70009687e-01,  1.93327945e+00],\n",
       "       [ 4.45689330e-01, -6.63851604e-01],\n",
       "       [-2.39274241e-01, -6.97238506e-01],\n",
       "       [ 2.52249144e+00, -1.07026456e+00],\n",
       "       [-2.47788720e-01,  7.29672865e-02],\n",
       "       [-5.19588239e-01, -3.20274156e-01],\n",
       "       [ 1.59157297e-01, -5.36987977e-02],\n",
       "       [-6.07497100e-01, -6.99478816e-01],\n",
       "       [ 1.37534170e+00,  2.74812071e+00],\n",
       "       [-6.49556052e-01, -7.63033015e-01],\n",
       "       [-6.70651930e-01, -7.20227485e-01],\n",
       "       [-2.69761936e-01,  1.09483940e+00],\n",
       "       [ 7.40579787e-01, -8.49951705e-01],\n",
       "       [ 8.17380761e-01,  5.38064248e-01],\n",
       "       [-4.27946262e-01, -7.31888811e-01],\n",
       "       [ 9.38008357e-01,  3.86385714e-01],\n",
       "       [-2.90992707e-01, -7.51246794e-01],\n",
       "       [-6.16351189e-01,  8.31643526e-01],\n",
       "       [-6.04964016e-01, -7.15769392e-01],\n",
       "       [ 2.54195127e-01,  5.29065951e-01],\n",
       "       [-3.76712990e-01,  6.23970852e-02],\n",
       "       [-5.67707995e-01,  6.33985534e-01],\n",
       "       [ 1.32740649e+00,  1.03211528e-01],\n",
       "       [-5.42429636e-01, -4.01632451e-01],\n",
       "       [ 1.69124689e-01, -7.95109615e-01],\n",
       "       [-6.71344672e-01, -7.52198980e-01],\n",
       "       [ 5.53036748e-01, -7.35047442e-01],\n",
       "       [ 6.24158910e+00, -1.67818026e+00],\n",
       "       [ 8.29502601e-01, -2.91341619e-01],\n",
       "       [ 8.94874454e-03,  4.42672370e-01],\n",
       "       [-6.36145556e-01, -4.97485473e-01],\n",
       "       [ 1.66698762e-01,  2.24199189e-01],\n",
       "       [-6.12958052e-01, -5.36908125e-01],\n",
       "       [ 7.28594654e-01, -2.66417223e-01],\n",
       "       [-2.53202267e-01, -5.25428886e-01],\n",
       "       [-6.65952197e-01,  2.71001919e-01],\n",
       "       [-5.73431554e-01, -6.50495164e-01],\n",
       "       [-5.03212760e-01,  7.61800752e-01],\n",
       "       [ 3.10716590e-01, -1.75247257e-01],\n",
       "       [ 2.91195419e+00,  8.22951362e-01],\n",
       "       [ 4.87066942e-02, -8.71086491e-01],\n",
       "       [-6.08677212e-01, -8.50880559e-01],\n",
       "       [-9.26631889e-01, -1.32908091e+00],\n",
       "       [-5.90311301e-01, -6.77501173e-01],\n",
       "       [-7.46699354e-01,  2.52574757e+00],\n",
       "       [-3.34067275e-01, -3.25288105e-01],\n",
       "       [-5.35969117e-01, -4.53944891e-01],\n",
       "       [-3.81603992e-01,  1.03846740e+00],\n",
       "       [-1.67282647e-02, -1.69274758e-01],\n",
       "       [-3.59300189e-01,  7.20156001e-02],\n",
       "       [-1.01010237e-01,  4.51285547e-01],\n",
       "       [-5.97716653e-01, -2.37355588e-01],\n",
       "       [ 8.13930723e-01, -2.51886788e+00],\n",
       "       [-3.03159480e-01, -4.77270928e-01],\n",
       "       [-5.98880863e-01, -7.82220580e-01],\n",
       "       [ 1.01530773e-01, -6.84084711e-01],\n",
       "       [-3.03298706e-01, -5.24575527e-01],\n",
       "       [-6.66638199e-01, -7.87413314e-01],\n",
       "       [-6.05312235e-01, -7.08079865e-01],\n",
       "       [-4.03698174e-01, -2.94058332e-01],\n",
       "       [-7.15770440e-01,  4.02181947e-01],\n",
       "       [-3.27226113e-01,  1.15257560e+00],\n",
       "       [-5.54033991e-01, -2.77412117e-01],\n",
       "       [-5.30902691e-01, -3.31980171e-01],\n",
       "       [ 8.13615567e-03, -5.62055130e-01],\n",
       "       [-7.26864339e-01,  1.63216042e-01],\n",
       "       [-7.47841424e-01, -8.01039534e-01],\n",
       "       [ 2.07784001e+00, -2.39260971e-01],\n",
       "       [-5.91834274e-01, -7.18485290e-01],\n",
       "       [-6.00950883e-01, -5.96204808e-01],\n",
       "       [-6.74064210e-01, -8.18007818e-01],\n",
       "       [-5.58294998e-01, -2.24201324e-01],\n",
       "       [-3.50019993e-01, -5.68904428e-01],\n",
       "       [-6.04977675e-01, -6.79487312e-01],\n",
       "       [-4.66966072e-01, -9.91631792e-01],\n",
       "       [-5.73431554e-01, -6.50495164e-01],\n",
       "       [-6.38137464e-01, -4.72432051e-01],\n",
       "       [ 1.68702363e+00,  2.52066889e-01],\n",
       "       [-3.19105607e-01, -7.20064063e-01],\n",
       "       [-6.85218901e-01, -7.73686159e-01],\n",
       "       [-4.37072671e-01, -7.00350369e-01],\n",
       "       [-4.51768422e-01, -2.57034035e-01],\n",
       "       [-5.73431554e-01, -6.50495164e-01],\n",
       "       [-5.82732526e-01, -5.62349894e-01],\n",
       "       [ 1.32942830e-01, -1.08077688e+00],\n",
       "       [-5.84837316e-01, -3.93528063e-01],\n",
       "       [-8.70590924e-01, -7.06944270e-01],\n",
       "       [-7.77862881e-01, -8.92551133e-01],\n",
       "       [-6.14808754e-01, -5.68736419e-01],\n",
       "       [-5.92992409e-01, -6.83083050e-01],\n",
       "       [-6.29445453e-01, -6.86916596e-01],\n",
       "       [-7.17472331e-01, -7.25386115e-01],\n",
       "       [-6.00422241e-01, -6.24276011e-01],\n",
       "       [ 5.48256025e-01,  8.17070890e-02],\n",
       "       [-3.68312762e-02,  3.20585275e-02],\n",
       "       [-5.73431554e-01, -6.50495164e-01],\n",
       "       [-1.40556198e-01,  7.53480754e-01],\n",
       "       [-5.73431554e-01, -6.50495164e-01],\n",
       "       [-7.45771602e-01, -7.20696717e-01],\n",
       "       [ 3.06635330e+00, -8.58127037e-01],\n",
       "       [-2.13743219e-01,  5.86013590e-01],\n",
       "       [-5.73431554e-01, -6.50495164e-01],\n",
       "       [ 1.53337989e+00,  1.19493056e+00],\n",
       "       [-5.56746676e-01, -1.51468963e-01],\n",
       "       [-5.24783588e-01, -8.58434193e-02],\n",
       "       [-3.73057163e-01,  5.13613090e-01],\n",
       "       [ 5.51865530e-01,  7.41185314e-01],\n",
       "       [-6.25929095e-01, -5.64423331e-01],\n",
       "       [-1.79053518e-01,  7.14245023e-01],\n",
       "       [-5.32898406e-01,  2.10340538e-01],\n",
       "       [ 1.59268818e+00,  3.78710690e+00],\n",
       "       [-5.23340637e-01,  4.07135788e-01],\n",
       "       [-2.05710688e-01,  2.76901079e-01],\n",
       "       [-3.11781487e-01, -5.87523156e-01],\n",
       "       [-3.43657678e-01,  5.20832024e-02],\n",
       "       [-1.05347526e-01,  2.24459409e+00],\n",
       "       [-5.82355473e-01, -6.44104388e-01],\n",
       "       [-6.26996152e-01, -6.11400913e-01],\n",
       "       [-3.11214077e-01, -6.31889170e-01],\n",
       "       [-3.99666328e-01, -7.87493170e-01],\n",
       "       [-6.03117441e-01, -6.38472743e-01],\n",
       "       [-1.40188733e-01,  4.84811532e-01],\n",
       "       [-1.80102359e-01,  1.48864868e-01],\n",
       "       [ 1.18600068e-03,  4.41987243e-01],\n",
       "       [-3.94779613e-01,  9.12030740e-01],\n",
       "       [-1.63731585e-01,  1.67500781e-01],\n",
       "       [ 8.38309313e-01,  2.19671982e+00],\n",
       "       [ 7.85018930e-01,  7.24700198e-01],\n",
       "       [-6.39903698e-01, -5.82987051e-01],\n",
       "       [ 1.00234526e-01,  2.35216080e-02],\n",
       "       [ 8.72754690e-01, -1.81907419e-01],\n",
       "       [-4.25789084e-01,  2.56268437e-01],\n",
       "       [ 4.74960769e-01,  4.41550518e+00],\n",
       "       [-6.54687134e-01, -7.59028250e-01],\n",
       "       [-5.88419639e-01,  7.89019154e-01],\n",
       "       [-2.43229163e+00, -2.80660221e+00],\n",
       "       [-5.72173364e-01, -5.60779334e-01],\n",
       "       [-5.73431554e-01, -6.50495164e-01],\n",
       "       [ 4.86188194e-01,  1.57552515e+00],\n",
       "       [-6.37496953e-01, -4.91637961e-01],\n",
       "       [-5.92152303e-01, -5.53793117e-01],\n",
       "       [ 2.89353798e-02,  2.41036237e+00],\n",
       "       [-5.23418124e-01, -1.20484642e-01],\n",
       "       [-2.50833261e-01, -3.49022558e-01],\n",
       "       [-5.73431554e-01, -6.50495164e-01],\n",
       "       [-2.11765837e-01,  7.29268870e-02],\n",
       "       [ 2.09023363e-01,  9.88270942e-01],\n",
       "       [-5.73431554e-01, -6.50495164e-01],\n",
       "       [-6.20826199e-02,  9.91838873e-01],\n",
       "       [-6.55842762e-01, -9.98141056e-02],\n",
       "       [ 8.28694513e-01,  1.73333493e+00],\n",
       "       [-1.76818800e-01,  6.10014390e-01],\n",
       "       [-5.73431554e-01, -6.50495164e-01],\n",
       "       [-2.53202267e-01, -5.25428886e-01],\n",
       "       [ 5.59245403e-01,  1.29577707e+00],\n",
       "       [-5.73431554e-01, -6.50495164e-01],\n",
       "       [-5.66745763e-01,  3.80858232e-02],\n",
       "       [-4.25950537e-01, -2.64517506e-01],\n",
       "       [-5.84790555e-01, -3.98999076e-01],\n",
       "       [-6.43382798e-01, -5.29727945e-01],\n",
       "       [-2.85457568e-01, -4.85701558e-01],\n",
       "       [-5.95156613e-01, -5.27171753e-01],\n",
       "       [-8.63614034e-02,  1.73490846e+00],\n",
       "       [-5.24753979e-01, -7.30059271e-01],\n",
       "       [-5.73431554e-01, -6.50495164e-01],\n",
       "       [-1.81682691e-01,  6.22467646e-02],\n",
       "       [-5.04526163e-01, -2.81537853e-01],\n",
       "       [-4.24208680e-01,  2.78770583e+00],\n",
       "       [-4.54512576e-01, -4.60907774e-01],\n",
       "       [ 1.91593421e-01,  8.53855006e-01],\n",
       "       [-5.73431554e-01, -6.50495164e-01],\n",
       "       [-4.96567434e-01,  5.20877183e-01],\n",
       "       [-1.07824645e-01,  6.17871691e-01],\n",
       "       [-5.59178519e-01, -3.40683087e-01],\n",
       "       [-7.43071541e-02,  4.51833929e-02],\n",
       "       [-5.73431554e-01, -6.50495164e-01],\n",
       "       [-6.18124138e-01, -5.14431069e-01],\n",
       "       [-6.21995019e-01, -6.50738983e-01],\n",
       "       [-5.73431554e-01, -6.50495164e-01],\n",
       "       [-5.75134342e-01, -6.62627123e-01],\n",
       "       [-1.44763055e-01,  4.42557972e-01],\n",
       "       [-6.46654109e-01, -6.95003689e-01],\n",
       "       [-5.65178653e-01, -2.98396978e-01],\n",
       "       [-5.73431554e-01, -6.50495164e-01],\n",
       "       [-5.74950592e-01,  1.31341652e-01],\n",
       "       [-6.63649216e-01, -3.43835115e-01],\n",
       "       [-5.54970113e-01, -2.66745195e-01],\n",
       "       [ 6.04776944e-01, -6.59850432e-01],\n",
       "       [-1.07780466e+00,  5.07093593e+00],\n",
       "       [-4.18466527e-01, -8.24888920e-01],\n",
       "       [-4.63968164e-01, -6.14820720e-01],\n",
       "       [-5.01503577e-01, -3.21340847e-01],\n",
       "       [-5.06359152e-01, -5.93874249e-01],\n",
       "       [-6.01761697e-01, -6.66223555e-01],\n",
       "       [-4.78279189e-01, -6.15947523e-01],\n",
       "       [-6.60311539e-01, -3.77355509e-01],\n",
       "       [-8.65172942e-01, -3.56879954e-01],\n",
       "       [-4.97408510e-01, -5.92090186e-02],\n",
       "       [-3.25201229e-01, -5.95938861e-01],\n",
       "       [-6.11797138e-01, -5.31614526e-01],\n",
       "       [ 5.27199454e-02, -1.78106489e-01],\n",
       "       [-5.07925188e-01,  7.41815313e-02],\n",
       "       [-5.73508430e-01, -6.60137936e-01],\n",
       "       [-6.61198807e-01, -2.56843855e-01],\n",
       "       [-8.71385637e-01,  4.14760436e-01],\n",
       "       [ 5.79149446e-01,  1.56301579e+00],\n",
       "       [-5.73431554e-01, -6.50495164e-01],\n",
       "       [ 3.08139078e-03,  4.47009780e+00],\n",
       "       [ 1.30924085e+01,  1.04929430e+02],\n",
       "       [-5.73431554e-01, -6.50495164e-01],\n",
       "       [-4.96012512e-01,  2.10151807e-01],\n",
       "       [-3.89622860e-02,  1.63921378e+00],\n",
       "       [ 1.42891997e+00,  8.95958639e-01],\n",
       "       [-4.12886947e-01, -7.11270159e-01],\n",
       "       [-5.73431554e-01, -6.50495164e-01],\n",
       "       [-2.62955426e-01, -6.95376968e-02],\n",
       "       [-5.73431554e-01, -6.50495164e-01],\n",
       "       [ 1.96502257e+00,  1.24823220e+01],\n",
       "       [-5.70313685e-02,  1.01212019e+00],\n",
       "       [-3.81735589e-01,  2.61647467e-02],\n",
       "       [-4.29563684e-01,  8.72954264e-01],\n",
       "       [-2.87252139e-01, -7.09730069e-01],\n",
       "       [-4.55374406e-01,  1.01184253e+00],\n",
       "       [-5.73431554e-01, -6.50495164e-01],\n",
       "       [ 8.55429207e-01,  5.47882805e-01],\n",
       "       [-5.92334091e-01, -6.67060313e-01],\n",
       "       [-5.73431554e-01, -6.50495164e-01],\n",
       "       [-5.42084900e-01,  1.28571626e-01],\n",
       "       [-5.98754707e-01, -5.85606443e-01],\n",
       "       [-5.32393771e-01, -6.61799744e-02],\n",
       "       [-5.73431554e-01, -6.50495164e-01],\n",
       "       [-4.38370464e-01,  2.24159420e-01],\n",
       "       [-5.73431554e-01, -6.50495164e-01],\n",
       "       [-6.45877650e-01, -2.24476072e-01],\n",
       "       [-5.92334091e-01, -6.67060313e-01],\n",
       "       [-5.92773753e-01, -6.73968227e-01],\n",
       "       [-5.75023735e-01, -6.25579722e-01],\n",
       "       [-1.15155545e+00, -4.51806386e-01],\n",
       "       [-5.92773753e-01, -6.73968227e-01],\n",
       "       [-5.56935166e-01, -2.17219127e-01],\n",
       "       [-5.00348324e-01,  1.21501312e-01],\n",
       "       [-5.73431554e-01, -6.50495164e-01],\n",
       "       [-5.84464131e-01, -6.30232161e-01],\n",
       "       [-5.26735157e-01, -1.12442558e-01],\n",
       "       [-3.44468435e-02, -3.31549875e-01],\n",
       "       [-3.58535419e-01, -5.22068868e-01],\n",
       "       [-5.93225297e-01, -5.64317845e-01],\n",
       "       [-5.92535325e-01, -6.76085169e-01],\n",
       "       [-5.92093413e-01, -6.67131490e-01],\n",
       "       [-5.87625294e-01, -1.55455487e-01],\n",
       "       [-8.90722207e-03, -5.97221721e-01],\n",
       "       [-5.79902305e-01, -5.01570143e-01],\n",
       "       [-2.63581079e-01, -3.43855335e-01],\n",
       "       [-6.63948896e-01, -7.60816753e-01],\n",
       "       [-5.73431554e-01, -6.50495164e-01],\n",
       "       [ 7.89631844e+00,  8.65667021e+00],\n",
       "       [ 1.33955310e+00,  4.17946320e+00],\n",
       "       [-2.00563685e-01,  9.98342875e-01],\n",
       "       [-6.88754180e-02, -4.16062003e-01],\n",
       "       [-5.73431554e-01, -6.50495164e-01],\n",
       "       [-4.38036806e-01,  1.72247338e+00],\n",
       "       [ 5.71035270e-02, -4.73186965e-01],\n",
       "       [-1.28844916e-01, -5.54324816e-01],\n",
       "       [-3.35962813e-01,  1.50656894e+00],\n",
       "       [-6.90175041e-01,  2.94926106e-02],\n",
       "       [-5.73431554e-01, -6.50495164e-01],\n",
       "       [-2.50635604e-01,  3.39743600e+00],\n",
       "       [-3.95954637e-01,  7.81416995e-01],\n",
       "       [-6.82954233e-01, -5.57646821e-01],\n",
       "       [-6.79616350e-01, -7.73784418e-01],\n",
       "       [-3.20866440e-01, -6.86469018e-01],\n",
       "       [-6.11702525e-01, -3.36738392e-01],\n",
       "       [-2.26703344e-01, -7.57376404e-01],\n",
       "       [-5.57155267e-01, -4.98867194e-01],\n",
       "       [ 3.38990919e-01, -2.31346160e-01],\n",
       "       [-6.81978832e-01, -7.12792623e-01],\n",
       "       [ 1.14197253e+00, -1.00672569e+00],\n",
       "       [-4.60448863e-01,  3.32113810e-01],\n",
       "       [-6.96798209e-01, -7.43696997e-01],\n",
       "       [-5.11815650e-01, -2.65498325e-02],\n",
       "       [-6.19675099e-01, -5.04187426e-01],\n",
       "       [-6.94436771e-01, -5.39689445e-01],\n",
       "       [-5.76707026e-01, -4.71199537e-01],\n",
       "       [-6.16690949e-01,  7.54572682e-01],\n",
       "       [-6.90191695e-01, -7.77826018e-01],\n",
       "       [-6.03449152e-01, -6.53898720e-01],\n",
       "       [-4.98028966e-01, -7.07330719e-01],\n",
       "       [-6.12958292e-01, -7.03811609e-01],\n",
       "       [-6.05072323e-01, -5.77538051e-01],\n",
       "       [-5.17090062e-01, -5.95820227e-01],\n",
       "       [-6.77351511e-01, -7.60091327e-01],\n",
       "       [-8.58874019e-01, -5.51898251e-01],\n",
       "       [-7.53160630e-01, -8.72687581e-01],\n",
       "       [-6.47700578e-01, -7.22148917e-01],\n",
       "       [-5.80899638e-01, -2.45744592e-01],\n",
       "       [-1.17724836e+00, -6.43879454e-01],\n",
       "       [-5.35015319e-01, -1.78325798e-01],\n",
       "       [-5.15068785e-01, -7.24645580e-01]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the new feature data\n",
    "X_std_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate our model and fit the data.\n",
    "svm = SVC(kernel = 'linear')\n",
    "svm.fit(X_std_pca, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7094594594594594"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.score(X_std_pca, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.70786517, 0.70786517, 0.70786517, 0.70786517, 0.71590909])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(svm, X_std_pca, Y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = .02  # step size in the mesh\n",
    " \n",
    "# create a mesh to plot in\n",
    "x_min, x_max = X_std_pca[:, 0].min() - 1, X_std_pca[:, 0].max() + 1\n",
    "y_min, y_max = X_std_pca[:, 1].min() - 1, X_std_pca[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "np.arange(y_min, y_max, h))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot also the training points\n",
    "plt.scatter(X[:, 0], X[:, 1], c=Y, cmap=plt.cm.coolwarm)\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.title('Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\femis\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "\n",
    " \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets\n",
    "\n",
    "\n",
    "# we create an instance of SVM and fit out data. We do not scale our\n",
    "# data since we want to plot the support vectors\n",
    "C = 1.0  # SVM regularization parameter\n",
    "\n",
    "svc = SVC(kernel = 'linear', C=C).fit(X_std_pca, y)\n",
    "rbf_svc = SVC(kernel='rbf', gamma=0.7, C=C).fit(X_std_pca, y)\n",
    "poly_svc = SVC(kernel='poly', degree=3, C=C).fit(X_std_pca, y)\n",
    "#lin_svc = LinearSVC(C=C).fit(X, y)\n",
    " \n",
    "# create a mesh to plot in\n",
    "# create a mesh to plot in\n",
    "x_min, x_max = X_std_pca[:, 0].min() - 1, X_std_pca[:, 0].max() + 1\n",
    "y_min, y_max = X_std_pca[:, 1].min() - 1, X_std_pca[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "np.arange(y_min, y_max, h))\n",
    " \n",
    "# title for the plots\n",
    "titles = ['SVC with linear kernel',\n",
    "'LinearSVC (linear kernel)',\n",
    "'SVC with RBF kernel',\n",
    "'SVC with polynomial (degree 3) kernel']\n",
    " \n",
    "for i, clf in enumerate((svc, rbf_svc, poly_svc)):\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "# point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "    plt.subplot(2, 2, i + 1)\n",
    "plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    " \n",
    "Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    " \n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=0.8)\n",
    " \n",
    "# Plot also the training points\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.coolwarm)\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.title(titles[i])\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BoW with Logistic Regression\n",
    "\n",
    "Let's try a technique with some protection against overfitting due to extraneous features – logistic regression with ridge regularization (from ridge regression, also called L2 regularization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\femis\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(266, 1613) (266,)\n",
      "Training set score: 0.9699248120300752\n",
      "\n",
      "Test set score: 0.8764044943820225\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(penalty='l2') # No need to specify l2 as it's the default. But we put it for demonstration.\n",
    "train = lr.fit(X_train, y_train)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print('Training set score:', lr.score(X_train, y_train))\n",
    "print('\\nTest set score:', lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression performs a bit better than the random forest.\n",
    "\n",
    "## BoW with Gradient Boosting\n",
    "\n",
    "And finally, let's see what gradient boosting can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.9661654135338346\n",
      "\n",
      "Test set score: 0.8146067415730337\n"
     ]
    }
   ],
   "source": [
    "clf = ensemble.GradientBoostingClassifier()\n",
    "train = clf.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score:', clf.score(X_train, y_train))\n",
    "print('\\nTest set score:', clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like LOGISTIC REGRESSION is the winner, but there's room for improvement.\n",
    "\n",
    "## Same model, new inputs\n",
    "\n",
    "What if we feed the model a different novel by Jane Austen, like Emma? Will it be able to distinguish Austen from Carroll with the same level of accuracy if we insert a different sample of Austen's writing?\n",
    "\n",
    "First, we need to process Emma the same way we processed the other data, and combine it with the Alice data. Remember that for computation time concerns, we only took the first tenth of the Alice text. Emma is pretty long. So in order to get comparable length texts, we take the first sixtieth of Emma. Again, if you want to experiment, you can take the whole texts of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emma Woodhouse, handsome, clever, and rich, with a comfortable home and happy disposition, seemed to\n"
     ]
    }
   ],
   "source": [
    "# Clean the Emma data.\n",
    "emma = gutenberg.raw('austen-emma.txt')\n",
    "emma = re.sub(r'VOLUME \\w+', '', emma)\n",
    "emma = re.sub(r'CHAPTER \\w+', '', emma)\n",
    "emma = text_cleaner(emma[:int(len(emma)/60)])\n",
    "print(emma[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse our cleaned data.\n",
    "emma_doc = nlp(emma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group into sentences.\n",
    "persuasion_sents = [[sent, \"Austen\"] for sent in persuasion_doc.sents]\n",
    "emma_sents = [[sent, \"Austen\"] for sent in emma_doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 50\n",
      "Processing row 100\n",
      "Processing row 150\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Build a new Bag of Words data frame for Emma word counts.\n",
    "# We'll use the same common words from Alice and Persuasion.\n",
    "emma_sentences = pd.DataFrame(emma_sents)\n",
    "emma_bow = bow_features(emma_sentences, common_words)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set score: 0.7235772357723578\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>Austen</th>\n",
       "      <th>Carroll</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Austen</th>\n",
       "      <td>158</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carroll</th>\n",
       "      <td>56</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    Austen  Carroll\n",
       "row_0                   \n",
       "Austen      158       12\n",
       "Carroll      56       20"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we can model it!\n",
    "# Let's use logistic regression again.\n",
    "\n",
    "# Combine the Emma sentence data with the Alice data from the test set.\n",
    "X_Emma_test = np.concatenate((\n",
    "    X_train[y_train[y_train=='Carroll'].index],\n",
    "    emma_bow.drop(['text_sentence','text_source'], 1)\n",
    "), axis=0)\n",
    "y_Emma_test = pd.concat([y_train[y_train=='Carroll'],\n",
    "                         pd.Series(['Austen'] * emma_bow.shape[0])])\n",
    "\n",
    "# Model.\n",
    "print('\\nTest set score:', lr.score(X_Emma_test, y_Emma_test))\n",
    "lr_Emma_predicted = lr.predict(X_Emma_test)\n",
    "pd.crosstab(y_Emma_test, lr_Emma_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well look at that! NLP approaches are generally effective on the same type of material as they were trained on. It looks like this model is actually able to differentiate multiple works by Austen from Alice in Wonderland. Now the question is whether the model is very good at identifying Austen, or very good at identifying Alice in Wonderland, or both..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
     ]
    }
   ],
   "source": [
    "print(gutenberg.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
